import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import json
import os
from datetime import datetime
from typing import Dict, List, Any
import nbformat as nbf
from nbformat.v4 import new_notebook, new_code_cell, new_markdown_cell

class EDAGenerator:
    def __init__(self, output_dir: str = "notebooks"):
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
        
    def generate_eda_notebook(self, data: Dict, business_type: str, location: str, insights: List[str]) -> str:
        """Generate comprehensive EDA notebook with proper encoding"""
        
        notebook = new_notebook()
        
        # Add header with ASCII-only characters to avoid encoding issues
        header_cell = new_markdown_cell(f"""
# Exploratory Data Analysis
## {business_type.title()} in {location.title()}

**Generated on:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**Data Source:** Google Places & Trends API via Apify
""")
        notebook.cells.append(header_cell)
        
        # Import cells
        imports_cell = new_code_cell("""
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import json
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

plt.style.use('default')
sns.set_palette("husl")
%matplotlib inline
""")
        notebook.cells.append(imports_cell)
        
        # Data loading cell - use ASCII-safe representation
        data_str = self._safe_json_dump(data)
        data_cell = new_code_cell(f"""
# Load research data
research_data = {data_str}

# Convert to DataFrames for analysis
places_data = pd.DataFrame(research_data.get('places_data', []))
trends_data = pd.DataFrame(research_data.get('trends_data', []))

print("Data Overview:")
print(f"Places data: {{len(places_data)}} records")
print(f"Trends data: {{len(trends_data)}} records")
""")
        notebook.cells.append(data_cell)
        
        # Add EDA sections based on available data
        if data.get('places_data'):
            self._add_places_eda(notebook, data)
        
        if data.get('trends_data'):
            self._add_trends_eda(notebook, data)
        
        # Insights section - use ASCII only
        insights_cell = new_markdown_cell("""
# AI-Generated Insights

The following insights were generated by the EDA Agent based on the data analysis:
""")
        notebook.cells.append(insights_cell)
        
        for i, insight in enumerate(insights):
            # Clean insight text of any problematic characters
            clean_insight = self._clean_text(insight)
            insight_cell = new_markdown_cell(f"""
## Insight {i+1}
{clean_insight}
""")
            notebook.cells.append(insight_cell)
        
        # Save notebook with proper encoding
        filename = f"eda_{business_type.replace(' ', '_')}_{location.replace(' ', '_')}_{datetime.now().strftime('%Y%m%d_%H%M')}.ipynb"
        filepath = os.path.join(self.output_dir, filename)
        
        try:
            with open(filepath, 'w', encoding='utf-8') as f:
                nbf.write(notebook, f)
            print(f"âœ… EDA notebook saved: {filepath}")
            return filepath
        except UnicodeEncodeError as e:
            print(f"âš ï¸ Unicode error saving notebook: {e}")
            # Fallback: save without problematic characters
            return self._save_safe_notebook(notebook, business_type, location)
    
    def _safe_json_dump(self, data: Dict) -> str:
        """Convert data to JSON string with proper encoding handling"""
        try:
            return json.dumps(data, indent=2, ensure_ascii=False)
        except UnicodeEncodeError:
            # Fallback: use ASCII-only encoding
            return json.dumps(data, indent=2, ensure_ascii=True)
    
    def _clean_text(self, text: str) -> str:
        """Clean text of problematic Unicode characters"""
        # Replace common problematic Unicode characters with ASCII equivalents
        replacements = {
            'ðŸ“Š': '[CHART]',
            'ðŸ“ˆ': '[TREND]',
            'ðŸ“': '[LOCATION]',
            'âœ…': '[OK]',
            'âš ï¸': '[WARNING]',
            'ðŸ”': '[SEARCH]',
            'ðŸŽ¯': '[TARGET]',
            'ðŸ’¡': '[IDEA]',
            'ðŸš€': '[ROCKET]',
            'ðŸ¤–': '[ROBOT]',
            'ðŸŒ': '[GLOBE]',
            'ðŸ“Š': '[ANALYSIS]',
            'ðŸ““': '[NOTEBOOK]',
            'âŒ': '[ERROR]',
            'ðŸ”„': '[RETRY]'
        }
        
        clean_text = text
        for uni_char, ascii_repl in replacements.items():
            clean_text = clean_text.replace(uni_char, ascii_repl)
        
        return clean_text
    
    def _save_safe_notebook(self, notebook: nbf.NotebookNode, business_type: str, location: str) -> str:
        """Save notebook with ASCII-only content as fallback"""
        # Create a clean version without problematic characters
        clean_notebook = new_notebook()
        
        for cell in notebook.cells:
            if cell.cell_type == 'markdown':
                clean_source = self._clean_text(cell.source)
                clean_cell = new_markdown_cell(clean_source)
                clean_notebook.cells.append(clean_cell)
            else:
                clean_notebook.cells.append(cell)
        
        filename = f"eda_clean_{business_type.replace(' ', '_')}_{location.replace(' ', '_')}_{datetime.now().strftime('%Y%m%d_%H%M')}.ipynb"
        filepath = os.path.join(self.output_dir, filename)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            nbf.write(clean_notebook, f)
        
        print(f"âœ… Safe EDA notebook saved: {filepath}")
        return filepath
    
    def _add_places_eda(self, notebook: nbf.NotebookNode, data: Dict):
        """Add Places data EDA to notebook"""
        
        notebook.cells.append(new_markdown_cell("""
# Google Places Data Analysis
## Business Listings & Competitive Landscape
"""))
        
        # Basic stats
        stats_cell = new_code_cell("""
# Basic statistics for Places data
if not places_data.empty:
    print("Places Data Columns:", places_data.columns.tolist())
    print("\\nBasic Info:")
    print(places_data.info())
    print("\\nDescriptive Statistics:")
    print(places_data.describe())
else:
    print("No places data available")
""")
        notebook.cells.append(stats_cell)
        
        # Rating analysis
        rating_cell = new_code_cell("""
# Rating Distribution Analysis
if 'rating' in places_data.columns and not places_data.empty:
    plt.figure(figsize=(12, 4))
    
    plt.subplot(1, 2, 1)
    places_data['rating'].hist(bins=20, alpha=0.7, edgecolor='black')
    plt.title('Distribution of Business Ratings')
    plt.xlabel('Rating')
    plt.ylabel('Frequency')
    
    plt.subplot(1, 2, 2)
    places_data['rating'].value_counts().sort_index().plot(kind='bar', alpha=0.7)
    plt.title('Rating Frequency')
    plt.xlabel('Rating')
    plt.ylabel('Count')
    
    plt.tight_layout()
    plt.show()
    
    print(f"Average Rating: {places_data['rating'].mean():.2f}")
    print(f"Rating Std Dev: {places_data['rating'].std():.2f}")
else:
    print("No rating data available")
""")
        notebook.cells.append(rating_cell)
        
        # Price level analysis
        price_cell = new_code_cell("""
# Price Level Analysis
if 'priceLevel' in places_data.columns and not places_data.empty:
    plt.figure(figsize=(10, 6))
    price_counts = places_data['priceLevel'].value_counts().sort_index()
    
    plt.subplot(1, 2, 1)
    price_counts.plot(kind='pie', autopct='%1.1f%%', startangle=90)
    plt.title('Price Level Distribution')
    
    plt.subplot(1, 2, 2)
    price_counts.plot(kind='bar', alpha=0.7)
    plt.title('Price Level Frequency')
    plt.xlabel('Price Level (1=Low, 4=High)')
    plt.ylabel('Count')
    
    plt.tight_layout()
    plt.show()
else:
    print("No price level data available")
""")
        notebook.cells.append(price_cell)
        
        # Review analysis
        review_cell = new_code_cell("""
# Review Analysis
if 'user_ratings_total' in places_data.columns and not places_data.empty:
    plt.figure(figsize=(10, 5))
    
    plt.subplot(1, 2, 1)
    places_data['user_ratings_total'].hist(bins=20, alpha=0.7, edgecolor='black')
    plt.title('Distribution of Review Counts')
    plt.xlabel('Number of Reviews')
    plt.ylabel('Frequency')
    
    plt.subplot(1, 2, 2)
    # Top 10 most reviewed businesses
    top_reviewed = places_data.nlargest(10, 'user_ratings_total')[['name', 'user_ratings_total', 'rating']]
    plt.barh(range(len(top_reviewed)), top_reviewed['user_ratings_total'])
    plt.yticks(range(len(top_reviewed)), top_reviewed['name'], fontsize=8)
    plt.title('Top 10 Most Reviewed Businesses')
    plt.xlabel('Number of Reviews')
    
    plt.tight_layout()
    plt.show()
    
    print(f"Total Reviews: {places_data['user_ratings_total'].sum()}")
    print(f"Average Reviews per Business: {places_data['user_ratings_total'].mean():.1f}")
else:
    print("No review data available")
""")
        notebook.cells.append(review_cell)
    
    def _add_trends_eda(self, notebook: nbf.NotebookNode, data: Dict):
        """Add Trends data EDA to notebook"""
        
        notebook.cells.append(new_markdown_cell("""
# Google Trends Data Analysis
## Market Interest & Search Patterns
"""))
        
        # Trends over time
        trends_cell = new_code_cell("""
# Trends Over Time Analysis
if 'date' in trends_data.columns and 'value' in trends_data.columns and not trends_data.empty:
    trends_data['date'] = pd.to_datetime(trends_data['date'])
    trends_sorted = trends_data.sort_values('date')
    
    plt.figure(figsize=(12, 6))
    plt.plot(trends_sorted['date'], trends_sorted['value'], marker='o', linewidth=2)
    plt.title('Search Interest Over Time')
    plt.xlabel('Date')
    plt.ylabel('Interest Score')
    plt.xticks(rotation=45)
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.show()
    
    # Calculate trend metrics
    if len(trends_sorted) > 1:
        growth = ((trends_sorted['value'].iloc[-1] - trends_sorted['value'].iloc[0]) / 
                 trends_sorted['value'].iloc[0] * 100)
        print(f"Overall Growth Rate: {growth:.2f}%")
        
        # Recent trend (last 4 points)
        if len(trends_sorted) >= 4:
            recent_growth = ((trends_sorted['value'].iloc[-1] - trends_sorted['value'].iloc[-4]) / 
                           trends_sorted['value'].iloc[-4] * 100)
            print(f"Recent Growth Rate (last 4 periods): {recent_growth:.2f}%")
else:
    print("No trends data available for time series analysis")
""")
        notebook.cells.append(trends_cell)
        
        # Top keywords
        keywords_cell = new_code_cell("""
# Top Keywords Analysis
if 'query' in trends_data.columns and not trends_data.empty:
    top_keywords = trends_data['query'].value_counts().head(10)
    
    if not top_keywords.empty:
        plt.figure(figsize=(10, 6))
        top_keywords.plot(kind='barh', alpha=0.7)
        plt.title('Top 10 Trending Keywords')
        plt.xlabel('Frequency')
        plt.gca().invert_yaxis()
        plt.tight_layout()
        plt.show()
    else:
        print("No keyword data available")
else:
    print("No query data available")
""")
        notebook.cells.append(keywords_cell)
        
        # Summary statistics
        summary_cell = new_code_cell("""
# Trends Summary Statistics
if not trends_data.empty:
    print("Trends Data Summary:")
    print(f"Total data points: {len(trends_data)}")
    print(f"Time period: {trends_data['date'].min()} to {trends_data['date'].max()}" if 'date' in trends_data.columns else "No date information")
    
    if 'value' in trends_data.columns:
        print(f"Average interest score: {trends_data['value'].mean():.2f}")
        print(f"Maximum interest score: {trends_data['value'].max()}")
        print(f"Minimum interest score: {trends_data['value'].min()}")
else:
    print("No trends data available for summary")
""")
        notebook.cells.append(summary_cell)